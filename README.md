# JobTech - Projet Data Warehouse & API

## Description

JobTech est un projet complet de Data Warehouse analysant le marchÃ© de l'emploi dans le domaine technologique. Il combine extraction de donnÃ©es, nettoyage, chargement en base PostgreSQL, et exposition via une API Django REST.

## Architecture du Projet

```
project/
â”œâ”€â”€ PIPELINE ETL
â”‚   â”œâ”€â”€ 01_scrape.py              # Extraction des donnÃ©es
â”‚   â”œâ”€â”€ 02_clean.py               # Nettoyage et transformation
â”‚   â”œâ”€â”€ 03_load_dwh.py            # Chargement en Data Warehouse
â”‚   â””â”€â”€ config.py                 # Configuration globale
â”œâ”€â”€ UTILITAIRES
â”‚   â”œâ”€â”€ utils/                    # Modules utilitaires
â”‚   â”‚   â”œâ”€â”€ extract/              # Extracteurs de donnÃ©es
â”‚   â”‚   â”œâ”€â”€ clean/                # Nettoyeurs de donnÃ©es
â”‚   â”‚   â””â”€â”€ load/                 # Chargeurs de donnÃ©es
â”œâ”€â”€ API REST
â”‚   â”œâ”€â”€ api/                      # Application Django
â”‚   â”‚   â”œâ”€â”€ jobtech_api/          # App principale
â”‚   â”‚   â”œâ”€â”€ manage.py             # Gestionnaire Django
â”‚   â”‚   â”œâ”€â”€ requirements.txt      # DÃ©pendances Python
â”‚   â”‚   â””â”€â”€ docker-compose.yml    # Configuration Docker
â”œâ”€â”€ DONNÃ‰ES
â”‚   â”œâ”€â”€ raw/                      # DonnÃ©es brutes
â”‚   â”œâ”€â”€ datasets_clean/           # DonnÃ©es nettoyÃ©es
â”œâ”€â”€ EXPORTS
â”‚   â”œâ”€â”€ jobtech_dwh_export.sql    # Export SQL du DWH
â”‚   â”œâ”€â”€ JobTech_API_Collection.postman_collection.json
â”‚   â””â”€â”€ JobTech_API_Environment.postman_environment.json
â””â”€â”€ DOCUMENTATION
    â”œâ”€â”€ README.md                 # Ce fichier
    â”œâ”€â”€ README_DWH_EXPORT.md     # Documentation export SQL
    â”œâ”€â”€ GUIDE_POSTMAN_JOBTECH.md # Guide API Postman
    â””â”€â”€ README_EXPORTS.md        # RÃ©capitulatif des exports
```

## PrÃ©requis

### Logiciels Requis
- **Python 3.10+** avec pip
- **PostgreSQL 12+** (ou Docker)
- **Postman** (pour tester l'API)

### DÃ©pendances Python
```bash
# Installation des dÃ©pendances principales
pip install pandas numpy requests beautifulsoup4 psycopg2-binary

# Pour l'API Django
pip install django djangorestframework django-cors-headers
```

## Installation et Lancement

### 1. Configuration de l'Environnement

#### Cloner et PrÃ©parer le Projet
```bash
# Cloner le projet
git clone https://github.com/brandgit/jobtech.git
cd jobtech

# CrÃ©er et activer un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# Installer les dÃ©pendances
pip install -r api/requirements.txt
```

#### Configuration de la Base de DonnÃ©es
```bash
# Option 1: PostgreSQL local
createdb jobtech_db
psql -d jobtech_db -c "CREATE USER jobtech_user WITH PASSWORD 'jobtech_pass';"
psql -d jobtech_db -c "GRANT ALL PRIVILEGES ON DATABASE jobtech_db TO jobtech_user;"

# Option 2: Docker PostgreSQL
cd api/
docker-compose up -d db
```

### 2. Pipeline ETL - Extraction et Chargement des DonnÃ©es

#### Ã‰tape 1: Extraction des DonnÃ©es
```bash
# Lancer l'extraction depuis les sources
python 01_scrape.py

# VÃ©rifier les donnÃ©es extraites
ls -la raw/
```

#### Ã‰tape 2: Nettoyage et Transformation
```bash
# Nettoyer et transformer les donnÃ©es
python 02_clean.py

# VÃ©rifier les donnÃ©es nettoyÃ©es
ls -la datasets_clean/
```

#### Ã‰tape 3: Chargement en Data Warehouse
```bash
# Charger les donnÃ©es dans PostgreSQL
python 03_load_dwh.py

# VÃ©rifier le chargement
psql -h localhost -p 5432 -U jobtech_user -d jobtech_db -c "SELECT COUNT(*) FROM d_skill;"
```

### 3. Lancement de l'API Django

#### PrÃ©parer l'API
```bash
# Aller dans le dossier API
cd api/

# Appliquer les migrations Django
python manage.py migrate

# CrÃ©er un superutilisateur (optionnel)
python manage.py createsuperuser

# Lancer le serveur de dÃ©veloppement
python manage.py runserver
```

#### VÃ©rifier l'API
```bash
# Tester l'API avec curl
curl http://localhost:8000/api/v1/health/

# RÃ©ponse attendue:
# {"status":"healthy","timestamp":"2025-07-05T...","database":"connected"}
```

### 4. Utilisation avec Postman

#### Importer les Collections
1. Ouvrir Postman
2. Importer `JobTech_API_Collection.postman_collection.json`
3. Importer `JobTech_API_Environment.postman_environment.json`
4. SÃ©lectionner l'environnement "JobTech API - Environnement"

#### Tester les Endpoints Prioritaires
```bash
# Endpoints spÃ©cifiques demandÃ©s 
GET /api/v1/google-trends/top_technologies/
GET /api/v1/developers/average_salary_by_employment/
GET /api/v1/developers/top_freelancer_job_titles/
GET /api/v1/developers/highest_paid_job_titles/
GET /api/v1/kaggle-datasets/best_paid_technology/
GET /api/v1/kaggle-datasets/junior_average_salary/
```

## Utilisation des Scripts

### Scripts Principaux

#### `01_scrape.py` - Extraction
```bash
# Extraction complÃ¨te
python 01_scrape.py

# Extraction sÃ©lective (par source)
python 01_scrape.py --source adzuna
python 01_scrape.py --source github
```

#### `02_clean.py` - Nettoyage
```bash
# Nettoyage complet
python 02_clean.py

# Nettoyage par type de donnÃ©es
python 02_clean.py --type jobs
python 02_clean.py --type skills
```

#### `03_load_dwh.py` - Chargement
```bash
# Chargement complet
python 03_load_dwh.py

# Chargement par table
python 03_load_dwh.py --table d_skill
python 03_load_dwh.py --table d_country
```

### Scripts d'Export

#### Export SQL du Data Warehouse
```bash
# GÃ©nÃ©rer un export SQL complet
python export_dwh_sql.py

# Fichier gÃ©nÃ©rÃ©: jobtech_dwh_export_YYYYMMDD_HHMMSS.sql
```

#### Test de l'API
```bash
# Tester tous les endpoints
cd api/
python test_api.py

# Tester endpoints spÃ©cifiques
python test_api.py --endpoint health
python test_api.py --endpoint google-trends
```

## Endpoints API Disponibles

### Tests et Monitoring
- `GET /api/v1/test/` - Test de base
- `GET /api/v1/health/` - Ã‰tat de l'API
- `GET /api/v1/data-freshness/` - FraÃ®cheur des donnÃ©es

### Endpoints SpÃ©cifiques DemandÃ©s
- `GET /api/v1/google-trends/top_technologies/` - Top 5 technologies
- `GET /api/v1/developers/average_salary_by_employment/` - Salaires par employment
- `GET /api/v1/developers/top_freelancer_job_titles/` - Top jobs freelance
- `GET /api/v1/developers/highest_paid_job_titles/` - Jobs les mieux payÃ©s
- `GET /api/v1/kaggle-datasets/best_paid_technology/` - Techno mieux payÃ©e
- `GET /api/v1/kaggle-datasets/junior_average_salary/` - Salaire moyen junior

### Tables de DonnÃ©es
- `GET /api/v1/d-dates/` - Dimension temporelle
- `GET /api/v1/d-countries/` - Pays
- `GET /api/v1/d-skills/` - CompÃ©tences
- `GET /api/v1/jobs/` - Offres d'emploi
- `GET /api/v1/developers/` - DÃ©veloppeurs
- `GET /api/v1/google-trends/` - Tendances Google

## DonnÃ©es Disponibles

### Sources de DonnÃ©es
- **Adzuna** : Offres d'emploi
- **GitHub** : Repositories et trends
- **Google Trends** : Tendances de recherche
- **Kaggle** : Datasets et salaires
- **RemoteOK** : Emplois remote
- **Stack Overflow** : EnquÃªtes dÃ©veloppeurs

### MÃ©triques Actuelles
- **Tables de dimensions** : 5 tables (4,964 lignes)
- **CompÃ©tences** : 919 technologies rÃ©fÃ©rencÃ©es
- **Pays** : 20 pays couverts
- **PÃ©riode** : 2020-2030 (dimension temporelle)

## Maintenance et Mise Ã  Jour

### Mise Ã  Jour des DonnÃ©es
```bash
# Pipeline complet de mise Ã  jour
python 01_scrape.py    # Nouvelles donnÃ©es
python 02_clean.py     # Nettoyage
python 03_load_dwh.py  # Chargement

# RedÃ©marrer l'API
cd api/
python manage.py runserver
```

### Sauvegarde et Restauration
```bash
# Sauvegarder le Data Warehouse
python export_dwh_sql.py
# GÃ©nÃ¨re: jobtech_dwh_export_YYYYMMDD_HHMMSS.sql

# Restaurer depuis une sauvegarde
psql -h localhost -p 5432 -U jobtech_user -d jobtech_db -f jobtech_dwh_export.sql
```

### Monitoring
```bash
# VÃ©rifier l'Ã©tat de l'API
curl http://localhost:8000/api/v1/health/

# VÃ©rifier les logs
tail -f api/logs/django.log

# VÃ©rifier la base de donnÃ©es
psql -h localhost -p 5432 -U jobtech_user -d jobtech_db -c "SELECT COUNT(*) FROM d_skill;"
```

## DÃ©pannage

### ProblÃ¨mes Courants

#### Base de DonnÃ©es Non Accessible
```bash
# VÃ©rifier que PostgreSQL est dÃ©marrÃ©
sudo systemctl status postgresql  # Linux
brew services list | grep postgresql  # Mac

# VÃ©rifier la connexion
psql -h localhost -p 5432 -U jobtech_user -d jobtech_db -c "SELECT version();"
```

#### API Non Accessible
```bash
# VÃ©rifier que l'API est dÃ©marrÃ©e
curl http://localhost:8000/api/v1/health/

# VÃ©rifier les logs Django
cd api/
python manage.py runserver --verbosity=2
```

#### DonnÃ©es Manquantes
```bash
# VÃ©rifier les donnÃ©es brutes
ls -la raw/

# VÃ©rifier les donnÃ©es nettoyÃ©es
ls -la datasets_clean/

# VÃ©rifier les tables en base
psql -h localhost -p 5432 -U jobtech_user -d jobtech_db -c "\dt"
```

### Logs et Debugging
```bash
# Activer le debug Django
cd api/
export DJANGO_DEBUG=True
python manage.py runserver

# VÃ©rifier les logs ETL
tail -f data_pipeline.log

# VÃ©rifier les requÃªtes SQL
psql -h localhost -p 5432 -U jobtech_user -d jobtech_db -c "SELECT pg_stat_activity.query FROM pg_stat_activity;"
```


# Test des endpoints avec curl
curl http://localhost:8000/api/v1/health/
curl http://localhost:8000/api/v1/google-trends/top_technologies/
```

## Ordre de Lancement RecommandÃ©

### 1. PremiÃ¨re Installation
```bash
# 1. PrÃ©parer l'environnement
python -m venv venv
source venv/bin/activate
pip install -r api/requirements.txt

# 2. Configurer la base de donnÃ©es
createdb jobtech_db
# ou docker-compose up -d db

# 3. Lancer le pipeline ETL
python 01_scrape.py
python 02_clean.py  
python 03_load_dwh.py

# 4. PrÃ©parer l'API
cd api/
python manage.py migrate
python manage.py runserver

# 5. Tester avec Postman
# Importer les collections et tester les endpoints
```

### 2. Utilisation Quotidienne
```bash
# 1. Mettre Ã  jour les donnÃ©es
python 01_scrape.py
python 02_clean.py
python 03_load_dwh.py

# 2. Lancer l'API
cd api/
python manage.py runserver

# 3. Utiliser l'API
curl http://localhost:8000/api/v1/health/
```

## Documentation

- **`README.md`** : Ce fichier (guide principal)
- **`README_DWH_EXPORT.md`** : Documentation de l'export SQL
- **`GUIDE_POSTMAN_JOBTECH.md`** : Guide d'utilisation Postman
- **`README_EXPORTS.md`** : RÃ©capitulatif des exports
- **`api/README.md`** : Documentation spÃ©cifique de l'API



## RÃ©sultats Attendus

AprÃ¨s avoir suivi ce guide, vous devriez avoir :

âœ… **Data Warehouse** : Base PostgreSQL avec 5 tables de dimensions  
âœ… **API REST** : 32 endpoints disponibles  
âœ… **6 Endpoints spÃ©cifiques** : Analyses demandÃ©es fonctionnelles  
âœ… **Collection Postman** : Tests API prÃªts Ã  l'emploi  
âœ… **Export SQL** : Sauvegarde complÃ¨te du DWH  
âœ… **Pipeline ETL** : Automatisation extraction â†’ nettoyage â†’ chargement  

---

**ðŸš€ Projet JobTech - Version 1.0**  
**ðŸ“… DerniÃ¨re mise Ã  jour** : 2025-07-05  
**ðŸ‘¥ Ã‰quipe** : Data Engineering & API Development  
**ðŸ“Š DonnÃ©es** : 4,964 enregistrements chargÃ©s  
**ðŸŽ¯ Endpoints** : 32 endpoints, 6 spÃ©cifiques opÃ©rationnels 